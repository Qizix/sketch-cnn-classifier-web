{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(); sns.set_style('dark')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cairosvg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'raw_path': '../data/raw/svg', 'png_path': '../data/precessed/png_images', 'precessed_path': '../data/precessed/tfrec', 'class_names': ['airplane', 'alarm clock', 'angel', 'ant', 'apple', 'arm', 'armchair', 'ashtray', 'axe', 'backpack', 'banana', 'barn', 'baseball bat', 'basket', 'bathtub', 'bear (animal)', 'bed', 'bee', 'beer-mug', 'bell', 'bench', 'bicycle', 'binoculars', 'blimp', 'book', 'bookshelf', 'boomerang', 'bottle opener', 'bowl', 'brain', 'bread', 'bridge', 'bulldozer', 'bus', 'bush', 'butterfly', 'cabinet', 'cactus', 'cake', 'calculator', 'camel', 'camera', 'candle', 'cannon', 'canoe', 'car (sedan)', 'carrot', 'castle', 'cat', 'cell phone', 'chair', 'chandelier', 'church', 'cigarette', 'cloud', 'comb', 'computer monitor', 'computer-mouse', 'couch', 'cow', 'crab', 'crane (machine)', 'crocodile', 'crown', 'cup', 'diamond', 'dog', 'dolphin', 'donut', 'door', 'door handle', 'dragon', 'duck', 'ear', 'elephant', 'envelope', 'eye', 'eyeglasses', 'face', 'fan', 'feather', 'fire hydrant', 'fish', 'flashlight', 'floor lamp', 'flower with stem', 'flying bird', 'flying saucer', 'foot', 'fork', 'frog', 'frying-pan', 'giraffe', 'grapes', 'grenade', 'guitar', 'hamburger', 'hammer', 'hand', 'harp', 'hat', 'head', 'head-phones', 'hedgehog', 'helicopter', 'helmet', 'horse', 'hot air balloon', 'hot-dog', 'hourglass', 'house', 'human-skeleton', 'ice-cream-cone', 'ipod', 'kangaroo', 'key', 'keyboard', 'knife', 'ladder', 'laptop', 'leaf', 'lightbulb', 'lighter', 'lion', 'lobster', 'loudspeaker', 'mailbox', 'megaphone', 'mermaid', 'microphone', 'microscope', 'monkey', 'moon', 'mosquito', 'motorbike', 'mouse (animal)', 'mouth', 'mug', 'mushroom', 'nose', 'octopus', 'owl', 'palm tree', 'panda', 'paper clip', 'parachute', 'parking meter', 'parrot', 'pear', 'pen', 'penguin', 'person sitting', 'person walking', 'piano', 'pickup truck', 'pig', 'pigeon', 'pineapple', 'pipe (for smoking)', 'pizza', 'potted plant', 'power outlet', 'present', 'pretzel', 'pumpkin', 'purse', 'rabbit', 'race car', 'radio', 'rainbow', 'revolver', 'rifle', 'rollerblades', 'rooster', 'sailboat', 'santa claus', 'satellite', 'satellite dish', 'saxophone', 'scissors', 'scorpion', 'screwdriver', 'sea turtle', 'seagull', 'shark', 'sheep', 'ship', 'shoe', 'shovel', 'skateboard', 'skull', 'skyscraper', 'snail', 'snake', 'snowboard', 'snowman', 'socks', 'space shuttle', 'speed-boat', 'spider', 'sponge bob', 'spoon', 'squirrel', 'standing bird', 'stapler', 'strawberry', 'streetlight', 'submarine', 'suitcase', 'sun', 'suv', 'swan', 'sword', 'syringe', 't-shirt', 'table', 'tablelamp', 'teacup', 'teapot', 'teddy-bear', 'telephone', 'tennis-racket', 'tent', 'tiger', 'tire', 'toilet', 'tomato', 'tooth', 'toothbrush', 'tractor', 'traffic light', 'train', 'tree', 'trombone', 'trousers', 'truck', 'trumpet', 'tv', 'umbrella', 'van', 'vase', 'violin', 'walkie talkie', 'wheel', 'wheelbarrow', 'windmill', 'wine-bottle', 'wineglass', 'wrist-watch', 'zebra']}, 'model': {'input_size': 256, 'output_size': 250, 'batch_size': 32}, 'training': {'checkpoint_dir': '../models/checkpoints/', 'final_model_dir': '../models/final/'}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../configs/config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Виведення конфігурації\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Constants\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m IMAGE_SIZE \u001b[38;5;241m=\u001b[39m (\u001b[43mconfig\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m NUM_CLASSES \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = (config['model']['input_size'], config['model']['input_size'])\n",
    "BATCH_SIZE = config['model']['batch_size']\n",
    "NUM_CLASSES = config['model']['output_size']\n",
    "PNG_DIR = config['data']['png_path']\n",
    "OUTPUT_DIR = config['data']['precessed_path']\n",
    "class_names = sorted(os.listdir(PNG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "# Set mixed precision policy\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 11:32:07.452723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737199927.519109   69456 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737199927.531334   69456 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-18 11:32:07.693409: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IMAGE_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 8\u001b[0m INPUT_SHAPE \u001b[38;5;241m=\u001b[39m \u001b[43mIMAGE_SIZE\u001b[49m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m3\u001b[39m,)  \u001b[38;5;66;03m# For 3-channel RGB images\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Функція для створення моделі аугментації\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_augmentation_model\u001b[39m():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMAGE_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom, RandomTranslation, Resizing\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INPUT_SHAPE = IMAGE_SIZE + (3,)  # For 3-channel RGB images\n",
    "\n",
    "# Функція для створення моделі аугментації\n",
    "def create_augmentation_model():\n",
    "    augmentation_model = Sequential([\n",
    "        Rescaling(1.0 / 255.0),  # Нормалізація зображень до [0, 1]\n",
    "        RandomFlip(\"horizontal\"),  # Випадковий горизонтальний переворот\n",
    "        RandomRotation(0.08),  # Випадковий обертання, максимум 8%\n",
    "        RandomZoom(0.08, 0.08),  # Випадкове масштабування: 8%\n",
    "        RandomTranslation(0.08, 0.08),  # Випадковий зсув: 8%\n",
    "        Resizing(*IMAGE_SIZE),  # Перевірка на правильний розмір\n",
    "    ])\n",
    "    return augmentation_model\n",
    "\n",
    "# Функція для попередньої обробки зображень\n",
    "def preprocess_image(file_path, label):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)  # Resize to the desired size\n",
    "    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "# Функція для аугментації зображень\n",
    "def augment_image(image, label, augmentation_model):\n",
    "    image = augmentation_model(image, training=True)  # Застосовуємо аугментацію\n",
    "    return image, label\n",
    "\n",
    "# Створення датасету (тепер повертає оброблені дані, а не tf.data.Dataset)\n",
    "def create_processed_data(images, labels, augmentation_model, is_training=True):\n",
    "    processed_images, processed_labels = [], []\n",
    "\n",
    "    for image_path, label in zip(images, labels):\n",
    "        # Preprocess the image\n",
    "        img, lbl = preprocess_image(image_path, label)\n",
    "\n",
    "        # Apply augmentation if training\n",
    "        if is_training:\n",
    "            img, lbl = augment_image(img, lbl, augmentation_model)\n",
    "\n",
    "        processed_images.append(img)\n",
    "        processed_labels.append(lbl)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    processed_images = tf.stack(processed_images)\n",
    "    processed_labels = tf.stack(processed_labels)\n",
    "\n",
    "    return processed_images, processed_labels\n",
    "\n",
    "# Поділ даних на тренувальний та валідаційний набори\n",
    "images = list(pathlib.Path(PNG_DIR).glob('*/*.png')) + list(pathlib.Path(PNG_DIR).glob('*/*.jpg'))\n",
    "images = [str(path) for path in images]\n",
    "labels = [os.path.basename(os.path.dirname(path)) for path in images]\n",
    "\n",
    "# Кодуємо мітки у формат one-hot\n",
    "label_to_index = {name: index for index, name in enumerate(sorted(set(labels)))}\n",
    "labels = [label_to_index[label] for label in labels]\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=len(label_to_index))  # Потрібно передати кількість класів\n",
    "\n",
    "# Розділяємо дані на тренувальний та валідаційний набори (80% для тренування, 20% для валідації)\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Створюємо модель аугментації\n",
    "augmentation_model = create_augmentation_model()\n",
    "\n",
    "# Створюємо оброблені дані\n",
    "train_images_processed, train_labels_processed = create_processed_data(train_images, train_labels, augmentation_model, is_training=True)\n",
    "val_images_processed, val_labels_processed = create_processed_data(val_images, val_labels, augmentation_model, is_training=False)\n",
    "\n",
    "# Тепер дані готові для збереження в TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zxc\n"
     ]
    }
   ],
   "source": [
    "def serialize_example(image, label):\n",
    "    # Convert the image to uint8 and encode it as JPEG\n",
    "    image = tf.cast(image * 255, tf.uint8)  # Scale back to [0, 255]\n",
    "    image = tf.io.encode_jpeg(image)  # Encode as JPEG\n",
    "    image = image.numpy()  # Convert to bytes\n",
    "\n",
    "    # Convert the label to an integer (from one-hot encoding)\n",
    "    label = tf.argmax(label).numpy()\n",
    "\n",
    "    # Create a TFRecord feature\n",
    "    feature = {\n",
    "        \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "def write_tfrecord(images, labels, filename):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for image, label in zip(images, labels):\n",
    "            example = serialize_example(image, label)\n",
    "            writer.write(example)\n",
    "\n",
    "# Save processed data to TFRecord files\n",
    "write_tfrecord(train_images_processed, train_labels_processed, \"train.tfrecord\")\n",
    "write_tfrecord(val_images_processed, val_labels_processed, \"val.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
